{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Anomaly Detection 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "**Anomaly detection** is the process of identifying data points, events, or observations that deviate significantly from the majority of the data. These deviations are called anomalies or outliers. \n",
    "\n",
    "**Purpose**: The primary purpose of anomaly detection is to identify rare items, events, or observations that raise suspicions by differing significantly from the majority of the data. This can be critical in various domains such as fraud detection, network security, fault detection, and monitoring of industrial processes.\n",
    "\n",
    "### Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "**Key Challenges**:\n",
    "1. **High Dimensionality**: As the number of features increases, the complexity of detecting anomalies also increases.\n",
    "2. **Lack of Labeled Data**: Often, labeled data for anomalies is scarce or unavailable, making supervised learning difficult.\n",
    "3. **Class Imbalance**: Anomalies are rare compared to normal instances, leading to a class imbalance problem.\n",
    "4. **Evolving Data**: In dynamic environments, data distributions can change over time, making it hard to maintain a consistent detection model.\n",
    "5. **Noise**: Distinguishing between noise and true anomalies can be challenging.\n",
    "6. **Computational Efficiency**: Real-time detection systems need to be efficient in terms of computation and memory usage.\n",
    "\n",
    "### Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "**Unsupervised Anomaly Detection**:\n",
    "- **No Labeled Data**: Does not require labeled training data.\n",
    "- **Techniques**: Often relies on clustering, statistical methods, or density estimation.\n",
    "- **Usage**: Suitable for scenarios where anomalies are not previously known.\n",
    "\n",
    "**Supervised Anomaly Detection**:\n",
    "- **Labeled Data**: Requires a labeled dataset with known normal and anomalous instances.\n",
    "- **Techniques**: Uses classification algorithms (e.g., SVM, neural networks).\n",
    "- **Usage**: Effective when historical data with labels is available.\n",
    "\n",
    "### Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "**Main Categories**:\n",
    "1. **Statistical Methods**: Use statistical properties and models to identify anomalies (e.g., Z-score, Grubbs' test).\n",
    "2. **Proximity-Based Methods**: Rely on the distance or density of data points (e.g., KNN, LOF).\n",
    "3. **Cluster-Based Methods**: Identify anomalies as points that do not fit well into any cluster (e.g., DBSCAN).\n",
    "4. **Classification-Based Methods**: Treat anomaly detection as a classification problem (e.g., SVM, neural networks).\n",
    "5. **Spectral Methods**: Use properties of eigenvalues and eigenvectors of data representations (e.g., PCA).\n",
    "6. **Isolation-Based Methods**: Identify anomalies by isolating points (e.g., Isolation Forest).\n",
    "\n",
    "### Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "**Main Assumptions**:\n",
    "1. **Anomalies are Distant**: Anomalous points are far from the majority of other points in the dataset.\n",
    "2. **Homogeneous Distribution**: Normal data points are close to each other in the feature space.\n",
    "3. **Distance Metrics**: The choice of distance metric (e.g., Euclidean, Manhattan) is critical and assumes that it effectively measures similarity in the context of the data.\n",
    "\n",
    "### Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "The **Local Outlier Factor (LOF)** algorithm computes anomaly scores by:\n",
    "1. **Local Density**: Estimating the local density of each point using a distance metric.\n",
    "2. **Reachability Distance**: Calculating the reachability distance of a point with respect to its neighbors.\n",
    "3. **Local Reachability Density (LRD)**: Inversely proportional to the average reachability distance of the point.\n",
    "4. **LOF Score**: Ratio of the LRD of a point to the LRD of its neighbors. A higher LOF score indicates a higher likelihood of being an anomaly.\n",
    "\n",
    "### Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "**Key Parameters**:\n",
    "1. **Number of Trees (n_estimators)**: Determines the number of isolation trees to build.\n",
    "2. **Subsample Size (max_samples)**: Number of samples to draw to train each isolation tree.\n",
    "3. **Contamination**: Proportion of outliers in the data, used to define the threshold on the decision function.\n",
    "4. **Max Features**: Number of features to consider when looking for the best split.\n",
    "\n",
    "### Q8. If a data point has only 2 neighbors of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "\n",
    "If a data point has only 2 neighbors of the same class within a radius of 0.5, its anomaly score using KNN with K=10 would be high. This is because the point does not have enough similar neighbors (only 2 out of the required 10), indicating it is an outlier relative to its surroundings. Exact anomaly scores depend on the specific implementation, but generally, fewer neighbors than expected in KNN signifies a higher anomaly score.\n",
    "\n",
    "### Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.167166353964689, 0.7957242830757882)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "n = 3000\n",
    "avg_path_length_data_point = 5.0\n",
    "\n",
    "# Harmonic number H(n-1)\n",
    "H_n_minus_1 = np.log(n-1) + 0.5772156649  # Euler-Mascheroni constant\n",
    "\n",
    "# Average path length c(n) for Isolation Forest\n",
    "c_n = 2 * H_n_minus_1 - (2 * (n-1) / n)\n",
    "\n",
    "# Anomaly score calculation\n",
    "anomaly_score = 2 ** (-avg_path_length_data_point / c_n)\n",
    "\n",
    "c_n, anomaly_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **COMPLETE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
