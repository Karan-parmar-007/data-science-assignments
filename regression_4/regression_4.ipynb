{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regression 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "**Lasso Regression** (Least Absolute Shrinkage and Selection Operator) is a type of linear regression that includes an L1 regularization term in its loss function. This regularization term penalizes the absolute values of the regression coefficients, which can lead to some coefficients being exactly zero, effectively performing feature selection.\n",
    "\n",
    "The Lasso Regression model is represented as:\n",
    "\n",
    "\\[ \\text{minimize} \\quad \\sum_{i=1}^{n} (y_i - \\mathbf{w}^T \\mathbf{x}_i)^2 + \\lambda \\sum_{j=1}^{p} |w_j| \\]\n",
    "\n",
    "Where:\n",
    "- \\( \\mathbf{w} \\) are the regression coefficients.\n",
    "- \\( \\lambda \\) is the regularization parameter.\n",
    "- \\( \\sum_{j=1}^{p} |w_j| \\) is the L1 penalty term.\n",
    "\n",
    "**Differences from Other Regression Techniques**:\n",
    "- **Ordinary Least Squares (OLS)**: OLS does not include any regularization term and minimizes only the residual sum of squares.\n",
    "- **Ridge Regression**: Uses an L2 regularization term (squared magnitude of coefficients), which does not perform feature selection as coefficients are shrunk but not set to zero.\n",
    "- **Elastic Net**: Combines both L1 and L2 regularization terms, balancing between Ridge and Lasso.\n",
    "\n",
    "### Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "The main advantage of Lasso Regression in feature selection is its ability to shrink some coefficients to exactly zero. This means it can effectively select a subset of the most important features, making the model simpler and potentially improving interpretability and performance, especially when dealing with high-dimensional data.\n",
    "\n",
    "### Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "In Lasso Regression, the interpretation of the coefficients is as follows:\n",
    "- **Non-zero Coefficients**: Each non-zero coefficient represents the change in the response variable for a one-unit change in the predictor variable, holding all other variables constant.\n",
    "- **Zero Coefficients**: Coefficients that are exactly zero indicate that the corresponding predictor variable is not important and has been excluded from the model.\n",
    "- The direction (positive or negative) of the non-zero coefficients indicates the nature of the relationship between the predictor and the response.\n",
    "\n",
    "### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "\n",
    "The main tuning parameter in Lasso Regression is the regularization parameter \\( \\lambda \\). The value of \\( \\lambda \\) controls the strength of the penalty on the coefficients:\n",
    "\n",
    "- **High \\( \\lambda \\)**: Leads to stronger penalization, which can result in more coefficients being shrunk to zero, performing more feature selection. However, too high a \\( \\lambda \\) might underfit the model.\n",
    "- **Low \\( \\lambda \\)**: Leads to weaker penalization, with fewer coefficients being shrunk to zero, resulting in a model closer to OLS regression. However, too low a \\( \\lambda \\) might overfit the model.\n",
    "\n",
    "Choosing the optimal \\( \\lambda \\) involves balancing bias and variance to achieve good predictive performance.\n",
    "\n",
    "### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "Yes, Lasso Regression can be used for non-linear regression problems by incorporating non-linear transformations of the input features. This can be achieved through:\n",
    "\n",
    "- **Polynomial Features**: Creating polynomial features (e.g., squares, cubes) of the original features to capture non-linear relationships.\n",
    "- **Interaction Terms**: Including interaction terms between different features.\n",
    "- **Basis Functions**: Using basis functions such as splines to model non-linear relationships.\n",
    "\n",
    "After these transformations, Lasso Regression can be applied to the expanded feature set to model non-linear relationships.\n",
    "\n",
    "### Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "The primary difference between Ridge Regression and Lasso Regression lies in the type of regularization they use:\n",
    "\n",
    "- **Ridge Regression**: Uses L2 regularization (squared magnitude of coefficients). It shrinks coefficients but does not set them exactly to zero, so all features are retained.\n",
    "- **Lasso Regression**: Uses L1 regularization (absolute value of coefficients). It can shrink some coefficients to exactly zero, effectively performing feature selection by excluding some features from the model.\n",
    "\n",
    "### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "Yes, Lasso Regression can handle multicollinearity in the input features. It does so by shrinking some of the coefficients to zero, effectively selecting only one or a few of the correlated features. This reduces the impact of multicollinearity and simplifies the model.\n",
    "\n",
    "### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    "The optimal value of the regularization parameter \\( \\lambda \\) in Lasso Regression is typically chosen using cross-validation:\n",
    "\n",
    "1. **Grid Search**: Define a grid of possible \\( \\lambda \\) values.\n",
    "2. **Cross-Validation**: For each \\( \\lambda \\) value, perform k-fold cross-validation and compute the cross-validated error for each \\( \\lambda \\).\n",
    "3. **Select \\( \\lambda \\)**: Choose the \\( \\lambda \\) that minimizes the cross-validated error.\n",
    "\n",
    "Additionally, techniques such as the Lasso path (a plot of coefficients as a function of \\( \\lambda \\)) can provide insights into how the coefficients change with different \\( \\lambda \\) values, helping in the selection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **COMPLETE**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
